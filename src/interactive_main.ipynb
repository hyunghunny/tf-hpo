{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import time\n",
    "import traceback\n",
    "\n",
    "import models.mnist_data as mnist\n",
    "from models.cnn_model1 import LeNet5\n",
    "from modules.hpvconf import HPVGenerator\n",
    "from modules.hpmgr import HPVManager\n",
    "from modules.trainmgr import TrainingManager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "LOG_PATH = \"../log/learning_rate_test1.csv\"\n",
    "TEMPLATE_PATH = 'CNN_HPV.ini'\n",
    "CONFIG_PATH = 'config/'\n",
    "NUM_GPUS = 1 # only one gpu can be used for HPOlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def run(params):\n",
    "    try:        \n",
    "        generator = HPVGenerator()\n",
    "        generator.setTemplate(TEMPLATE_PATH)\n",
    "        hpv_file = generator.generate(params, output_dir=CONFIG_PATH)\n",
    "                \n",
    "        train_manager = TrainingManager(LeNet5(mnist.import_dataset()), LOG_PATH)\n",
    "        train_manager.setTrainingDevices('gpu', NUM_GPUS)\n",
    "        train_manager.setLoggingParams([ hyperparam for hyperparam in params])\n",
    "        hpv = HPVManager(hpv_file, ini_dir=CONFIG_PATH)\n",
    "        return train_manager.run(hpv)\n",
    "           \n",
    "    except:\n",
    "        e = sys.exc_info()\n",
    "        print(\"Error: \" + str(e))\n",
    "        traceback.print_exc()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with /root/tf-hpolib/tf-hpo/src/config/HPV_14793166815787.ini is terminated properly\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "unhashable type: 'dict'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-fd1d39c715c2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0;31m#print str(params) + \" -> \" + str(result)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0mlearning_rate_results\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: unhashable type: 'dict'"
     ]
    }
   ],
   "source": [
    "use_decays = [True, False]\n",
    "learning_rates = [0.1, 0.01, 0.0005]\n",
    "learning_rate_results = {}\n",
    "for use_decay in use_decays:\n",
    "    for learning_rate in learning_rates:\n",
    "        params = {'USE_LEARNING_RATE_DECAY': use_decay, 'BASE_LEARNING_RATE': learning_rate}\n",
    "        result = run(params)\n",
    "        #print str(params) + \" -> \" + str(result)\n",
    "        learning_rate_results[str(params)] = result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with /root/tf-hpolib/tf-hpo/src/config/HPV_14786315748617.ini is terminated properly\n",
      "{'BASE_LEARNING_RATE': 0.005, 'USE_LEARNING_RATE_DECAY': True} -> 0.82\n",
      "Training with /root/tf-hpolib/tf-hpo/src/config/HPV_14786316795831.ini is terminated properly\n",
      "{'BASE_LEARNING_RATE': 0.02, 'USE_LEARNING_RATE_DECAY': True} -> 0.6\n",
      "Training with /root/tf-hpolib/tf-hpo/src/config/HPV_14786317871794.ini is terminated properly\n",
      "{'BASE_LEARNING_RATE': 0.05, 'USE_LEARNING_RATE_DECAY': True} -> 0.67\n",
      "Training with /root/tf-hpolib/tf-hpo/src/config/HPV_14786318938611.ini is terminated properly\n",
      "{'BASE_LEARNING_RATE': 0.001, 'USE_LEARNING_RATE_DECAY': True} -> 1.23\n",
      "Training with /root/tf-hpolib/tf-hpo/src/config/HPV_14786320018503.ini is terminated properly\n",
      "{'BASE_LEARNING_RATE': 0.0001, 'USE_LEARNING_RATE_DECAY': True} -> 3.56\n",
      "Training with /root/tf-hpolib/tf-hpo/src/config/HPV_14786321104892.ini is terminated properly\n",
      "{'BASE_LEARNING_RATE': 0.005, 'USE_LEARNING_RATE_DECAY': False} -> 0.79\n",
      "Training with /root/tf-hpolib/tf-hpo/src/config/HPV_14786322188903.ini is terminated properly\n",
      "{'BASE_LEARNING_RATE': 0.02, 'USE_LEARNING_RATE_DECAY': False} -> 0.77\n",
      "Training with /root/tf-hpolib/tf-hpo/src/config/HPV_14786323256931.ini is terminated properly\n",
      "{'BASE_LEARNING_RATE': 0.05, 'USE_LEARNING_RATE_DECAY': False} -> 0.85\n",
      "Training with /root/tf-hpolib/tf-hpo/src/config/HPV_14786324314156.ini is terminated properly\n",
      "{'BASE_LEARNING_RATE': 0.001, 'USE_LEARNING_RATE_DECAY': False} -> 1.14\n",
      "Training with /root/tf-hpolib/tf-hpo/src/config/HPV_14786325411443.ini is terminated properly\n",
      "{'BASE_LEARNING_RATE': 0.0001, 'USE_LEARNING_RATE_DECAY': False} -> 2.91\n"
     ]
    }
   ],
   "source": [
    "use_decays = [True, False]\n",
    "learning_rates = [0.005, 0.02, 0.05, 0.001, 0.0001]\n",
    "\n",
    "for use_decay in use_decays:\n",
    "    for learning_rate in learning_rates:\n",
    "        params = {'USE_LEARNING_RATE_DECAY': use_decay, 'BASE_LEARNING_RATE': learning_rate}\n",
    "        result = run(params)\n",
    "        learning_rate_results[str(params)] = result\n",
    "#print learning_rate_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* With learning rate decay\n",
    " * **{'BASE_LEARNING_RATE': 0.1}** -> 1.02\n",
    " * {'BASE_LEARNING_RATE': 0.05} -> 0.67\n",
    " * {'BASE_LEARNING_RATE': 0.02} -> 0.6\n",
    " * **{'BASE_LEARNING_RATE': 0.01}** -> 0.63\n",
    " * {'BASE_LEARNING_RATE': 0.005} -> 0.82\n",
    " * {'BASE_LEARNING_RATE': 0.001} -> 1.23\n",
    " * {'BASE_LEARNING_RATE': 0.0005} -> 1.51\n",
    " * **{'BASE_LEARNING_RATE': 0.0001}** -> 3.56\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Without learning rate decay\n",
    " * **{'BASE_LEARNING_RATE': 0.1}** -> 1.4\n",
    " * {'BASE_LEARNING_RATE': 0.05} -> 0.85\n",
    " * {'BASE_LEARNING_RATE': 0.02} -> 0.77\n",
    " * **{'BASE_LEARNING_RATE': 0.01}** -> 0.74\n",
    " * {'BASE_LEARNING_RATE': 0.005} -> 0.79\n",
    " * {'BASE_LEARNING_RATE': 0.001} -> 1.14\n",
    " * {'BASE_LEARNING_RATE': 0.0005} -> 1.29\n",
    " * **{'BASE_LEARNING_RATE': 0.0001}** -> 2.91\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- tested learning rate: 0.1, 0.05, 0.02, 0.01, 0.05, 0.001, 0.0005, 0.0001 (w/ and w/o learning rate decay (0.95))\n",
    "  * test error decreased near 0.02~0.01 and increased again \n",
    "    * test errors w/ learning late decay : 1.02, 0.67, 0.6, 0.63, 0.82,  1.23, 1.51, 3.56\n",
    "    * test errors w/o  learning late decay : 1.4, 0.85, 0.77, 0.74, 0.79, 1.14, 1.29, 2.91"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "LOG_PATH = \"../log/regularization_test.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with /root/tf-hpolib/tf-hpo/src/config/HPV_14786746824296.ini is terminated properly\n",
      "{'REGULARIZER_FACTOR': 0} -> 0.6%\n",
      "Training with /root/tf-hpolib/tf-hpo/src/config/HPV_14786747884366.ini is terminated properly\n",
      "{'REGULARIZER_FACTOR': 5e-05} -> 0.59%\n",
      "Training with /root/tf-hpolib/tf-hpo/src/config/HPV_14786748958402.ini is terminated properly\n",
      "{'REGULARIZER_FACTOR': 0.0001} -> 0.64%\n",
      "Training with /root/tf-hpolib/tf-hpo/src/config/HPV_14786750034210.ini is terminated properly\n",
      "{'REGULARIZER_FACTOR': 0.0002} -> 0.63%\n",
      "Training with /root/tf-hpolib/tf-hpo/src/config/HPV_14786751109682.ini is terminated properly\n",
      "{'REGULARIZER_FACTOR': 0.0003} -> 0.69%\n",
      "Training with /root/tf-hpolib/tf-hpo/src/config/HPV_14786752184817.ini is terminated properly\n",
      "{'REGULARIZER_FACTOR': 0.0004} -> 0.67%\n",
      "Training with /root/tf-hpolib/tf-hpo/src/config/HPV_14786753260488.ini is terminated properly\n",
      "{'REGULARIZER_FACTOR': 0.0006} -> 0.67%\n",
      "Training with /root/tf-hpolib/tf-hpo/src/config/HPV_14786754353644.ini is terminated properly\n",
      "{'REGULARIZER_FACTOR': 0.0007} -> 0.73%\n",
      "Training with /root/tf-hpolib/tf-hpo/src/config/HPV_14786755415479.ini is terminated properly\n",
      "{'REGULARIZER_FACTOR': 0.0008} -> 0.68%\n",
      "Training with /root/tf-hpolib/tf-hpo/src/config/HPV_14786756472820.ini is terminated properly\n",
      "{'REGULARIZER_FACTOR': 0.0009} -> 0.69%\n",
      "Training with /root/tf-hpolib/tf-hpo/src/config/HPV_14786757528500.ini is terminated properly\n",
      "{'REGULARIZER_FACTOR': 0.005} -> 0.99%\n",
      "Training with /root/tf-hpolib/tf-hpo/src/config/HPV_14786758584260.ini is terminated properly\n",
      "{'REGULARIZER_FACTOR': 0.05} -> 2.37%\n"
     ]
    }
   ],
   "source": [
    "regularization_factors = [0, 5e-5, 1e-4, 2e-4, 3e-4, 4e-4, 6e-4, 7e-4, 8e-4, 9e-4, 5e-3, 5e-2]\n",
    "regularization_results = {}\n",
    "for regularization_factor in regularization_factors:\n",
    "    params = {'REGULARIZER_FACTOR': regularization_factor}\n",
    "    result = run(params)\n",
    "    #print str(params) + \" -> \" + str(result) + \"%\"\n",
    "    regularization_results[str(params)] = result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with /root/tf-hpolib/tf-hpo/src/config/HPV_14786787480803.ini is terminated properly\n",
      "{'REGULARIZER_FACTOR': 5e-08} -> 0.67%\n",
      "Training with /root/tf-hpolib/tf-hpo/src/config/HPV_14786788520223.ini is terminated properly\n",
      "{'REGULARIZER_FACTOR': 5e-07} -> 0.67%\n",
      "Training with /root/tf-hpolib/tf-hpo/src/config/HPV_14786789605891.ini is terminated properly\n",
      "{'REGULARIZER_FACTOR': 5e-06} -> 0.7%\n",
      "Training with /root/tf-hpolib/tf-hpo/src/config/HPV_14786790696790.ini is terminated properly\n",
      "{'REGULARIZER_FACTOR': 0.5} -> 4.32%\n",
      "Training with /root/tf-hpolib/tf-hpo/src/config/HPV_14786791791477.ini is terminated properly\n",
      "{'REGULARIZER_FACTOR': 0.4} -> 3.16%\n",
      "Training with /root/tf-hpolib/tf-hpo/src/config/HPV_14786792882536.ini is terminated properly\n",
      "{'REGULARIZER_FACTOR': 0.3} -> 2.97%\n",
      "Training with /root/tf-hpolib/tf-hpo/src/config/HPV_14786793987900.ini is terminated properly\n",
      "{'REGULARIZER_FACTOR': 0.2} -> 2.64%\n",
      "Training with /root/tf-hpolib/tf-hpo/src/config/HPV_14786795079631.ini is terminated properly\n",
      "{'REGULARIZER_FACTOR': 0.1} -> 2.12%\n"
     ]
    }
   ],
   "source": [
    "regularization_factors = [5e-8, 5e-7, 5e-6, 5e-1, 4e-1, 3e-1, 2e-1, 1e-1]\n",
    "\n",
    "for regularization_factor in regularization_factors:\n",
    "    params = {'REGULARIZER_FACTOR': regularization_factor}\n",
    "    result = run(params)\n",
    "    #print str(params) + \" -> \" + str(result) + \"%\"\n",
    "    regularization_results[str(params)] = result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* {'REGULARIZER_FACTOR': 0} -> 0.6%\n",
    "* {'REGULARIZER_FACTOR': 5e-08} -> 0.67%\n",
    "* {'REGULARIZER_FACTOR': 5e-07} -> 0.67%\n",
    "* {'REGULARIZER_FACTOR': 5e-06} -> 0.7%\n",
    "* {'REGULARIZER_FACTOR': 5e-05} -> 0.59%\n",
    "* {'REGULARIZER_FACTOR': 0.0001} -> 0.64%\n",
    "* {'REGULARIZER_FACTOR': 0.0002} -> 0.63%\n",
    "* {'REGULARIZER_FACTOR': 0.0003} -> 0.69%\n",
    "* {'REGULARIZER_FACTOR': 0.0004} -> 0.67%\n",
    "* {'REGULARIZER_FACTOR': 0.0006} -> 0.67%\n",
    "* {'REGULARIZER_FACTOR': 0.0007} -> 0.73%\n",
    "* {'REGULARIZER_FACTOR': 0.0008} -> 0.68%\n",
    "* {'REGULARIZER_FACTOR': 0.005} -> 0.99%\n",
    "* {'REGULARIZER_FACTOR': 0.05} -> 2.37%\n",
    "* {'REGULARIZER_FACTOR': 0.1} -> 2.12%\n",
    "* {'REGULARIZER_FACTOR': 0.2} -> 2.64%\n",
    "* {'REGULARIZER_FACTOR': 0.3} -> 2.97%\n",
    "* {'REGULARIZER_FACTOR': 0.4} -> 3.16%\n",
    "* {'REGULARIZER_FACTOR': 0.5} -> 4.32%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After regularizer factor testing, followings may be effective:\n",
    " * 0 ~ 0.001 : 0.6? % -> choose **5e-05**\n",
    " * 0.005 ~ 0.05 : 0.99% ~ 2.37% -> choose **0.02**\n",
    " * other : choose **0.5**  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "LOG_PATH = \"../log/dropout_test.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with /root/tf-hpolib/tf-hpo/src/config/HPV_14786818570633.ini is terminated properly\n",
      "{'DROPOUT_RATE': 0.9} -> 0.77%\n",
      "Training with /root/tf-hpolib/tf-hpo/src/config/HPV_14786819626294.ini is terminated properly\n",
      "{'DROPOUT_RATE': 0.8} -> 0.77%\n",
      "Training with /root/tf-hpolib/tf-hpo/src/config/HPV_14786820733148.ini is terminated properly\n",
      "{'DROPOUT_RATE': 0.75} -> 0.73%\n",
      "Training with /root/tf-hpolib/tf-hpo/src/config/HPV_14786821833540.ini is terminated properly\n",
      "{'DROPOUT_RATE': 0.7} -> 0.69%\n",
      "Training with /root/tf-hpolib/tf-hpo/src/config/HPV_14786822936462.ini is terminated properly\n",
      "{'DROPOUT_RATE': 0.6} -> 0.75%\n",
      "Training with /root/tf-hpolib/tf-hpo/src/config/HPV_14786824038998.ini is terminated properly\n",
      "{'DROPOUT_RATE': 0.4} -> 0.68%\n",
      "Training with /root/tf-hpolib/tf-hpo/src/config/HPV_14786825145771.ini is terminated properly\n",
      "{'DROPOUT_RATE': 0.3} -> 0.75%\n",
      "Training with /root/tf-hpolib/tf-hpo/src/config/HPV_14786826249595.ini is terminated properly\n",
      "{'DROPOUT_RATE': 0.25} -> 0.58%\n",
      "Training with /root/tf-hpolib/tf-hpo/src/config/HPV_14786827353664.ini is terminated properly\n",
      "{'DROPOUT_RATE': 0.2} -> 0.73%\n",
      "Training with /root/tf-hpolib/tf-hpo/src/config/HPV_14786828474703.ini is terminated properly\n",
      "{'DROPOUT_RATE': 0.1} -> 0.89%\n",
      "(<type 'exceptions.ValueError'>, ValueError('keep_prob must be a scalar tensor or a float in the range (0, 1], got 0',), <traceback object at 0x7f014435eab8>)\n",
      "{'DROPOUT_RATE': 0.0} -> None%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"models/cnn_model.py\", line 79, in learn\n",
      "    y = self.train()\n",
      "  File \"models/cnn_model.py\", line 107, in train\n",
      "    logits = self.leNet5(self.train_data_node, True)\n",
      "  File \"models/cnn_model.py\", line 392, in leNet5\n",
      "    hidden = tf.nn.dropout(hidden, 1.0 - self.hp[\"DROPOUT_RATE\"], seed=self.hp[\"SEED\"])\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/nn_ops.py\", line 1114, in dropout\n",
      "    \"range (0, 1], got %g\" % keep_prob)\n",
      "ValueError: keep_prob must be a scalar tensor or a float in the range (0, 1], got 0\n"
     ]
    }
   ],
   "source": [
    "dropouts = [1, 0.9, 0.8, 0.75, 0.7, 0.6, 0.4, 0.3, 0.25, 0.2, 0.1]\n",
    "dropouts_result = {}\n",
    "for dropout in dropouts:\n",
    "    params = {'DROPOUT_RATE': dropout}\n",
    "    result = run(params)\n",
    "    #print str(params) + \" -> \" + str(result) + \"%\"\n",
    "    dropouts_result(str(params)) = result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "following dropout rates are selected: **1.0, 0.75, 0.25**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "LOG_PATH = \"../log/reg_mix_test.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with /root/tf-hpolib/tf-hpo/src/config/HPV_14786915277472.ini is terminated properly\n",
      "{'DROPOUT_RATE': 1.0, 'BASE_LEARNING_RATE': 0.1, 'REGULARIZER_FACTOR': 5e-05, 'USE_LEARNING_RATE_DECAY': True} -> 1.71%\n",
      "Training with /root/tf-hpolib/tf-hpo/src/config/HPV_14786916317935.ini is terminated properly\n",
      "{'DROPOUT_RATE': 0.75, 'BASE_LEARNING_RATE': 0.1, 'REGULARIZER_FACTOR': 5e-05, 'USE_LEARNING_RATE_DECAY': True} -> 89.72%\n",
      "Training with /root/tf-hpolib/tf-hpo/src/config/HPV_14786917411138.ini is terminated properly\n",
      "{'DROPOUT_RATE': 0.25, 'BASE_LEARNING_RATE': 0.1, 'REGULARIZER_FACTOR': 5e-05, 'USE_LEARNING_RATE_DECAY': True} -> 89.72%\n",
      "Training with /root/tf-hpolib/tf-hpo/src/config/HPV_14786918492949.ini is terminated properly\n",
      "{'DROPOUT_RATE': 1.0, 'BASE_LEARNING_RATE': 0.1, 'REGULARIZER_FACTOR': 0.25, 'USE_LEARNING_RATE_DECAY': True} -> 90.2%\n",
      "Training with /root/tf-hpolib/tf-hpo/src/config/HPV_14786919573739.ini is terminated properly\n",
      "{'DROPOUT_RATE': 0.75, 'BASE_LEARNING_RATE': 0.1, 'REGULARIZER_FACTOR': 0.25, 'USE_LEARNING_RATE_DECAY': True} -> 90.2%\n",
      "Training with /root/tf-hpolib/tf-hpo/src/config/HPV_14786920646355.ini is terminated properly\n",
      "{'DROPOUT_RATE': 0.25, 'BASE_LEARNING_RATE': 0.1, 'REGULARIZER_FACTOR': 0.25, 'USE_LEARNING_RATE_DECAY': True} -> 2.53%\n",
      "Training with /root/tf-hpolib/tf-hpo/src/config/HPV_14786921735504.ini is terminated properly\n",
      "{'DROPOUT_RATE': 1.0, 'BASE_LEARNING_RATE': 0.1, 'REGULARIZER_FACTOR': 0.5, 'USE_LEARNING_RATE_DECAY': True} -> 90.2%\n",
      "Training with /root/tf-hpolib/tf-hpo/src/config/HPV_14786922819023.ini is terminated properly\n",
      "{'DROPOUT_RATE': 0.75, 'BASE_LEARNING_RATE': 0.1, 'REGULARIZER_FACTOR': 0.5, 'USE_LEARNING_RATE_DECAY': True} -> 90.2%\n",
      "Training with /root/tf-hpolib/tf-hpo/src/config/HPV_14786923906304.ini is terminated properly\n",
      "{'DROPOUT_RATE': 0.25, 'BASE_LEARNING_RATE': 0.1, 'REGULARIZER_FACTOR': 0.5, 'USE_LEARNING_RATE_DECAY': True} -> 90.2%\n",
      "Training with /root/tf-hpolib/tf-hpo/src/config/HPV_14786924995353.ini is terminated properly\n",
      "{'DROPOUT_RATE': 1.0, 'BASE_LEARNING_RATE': 0.01, 'REGULARIZER_FACTOR': 5e-05, 'USE_LEARNING_RATE_DECAY': True} -> 0.9%\n",
      "Training with /root/tf-hpolib/tf-hpo/src/config/HPV_14786926092775.ini is terminated properly\n",
      "{'DROPOUT_RATE': 0.75, 'BASE_LEARNING_RATE': 0.01, 'REGULARIZER_FACTOR': 5e-05, 'USE_LEARNING_RATE_DECAY': True} -> 0.78%\n",
      "Training with /root/tf-hpolib/tf-hpo/src/config/HPV_14786927191412.ini is terminated properly\n",
      "{'DROPOUT_RATE': 0.25, 'BASE_LEARNING_RATE': 0.01, 'REGULARIZER_FACTOR': 5e-05, 'USE_LEARNING_RATE_DECAY': True} -> 0.71%\n",
      "Training with /root/tf-hpolib/tf-hpo/src/config/HPV_14786928291953.ini is terminated properly\n",
      "{'DROPOUT_RATE': 1.0, 'BASE_LEARNING_RATE': 0.01, 'REGULARIZER_FACTOR': 0.25, 'USE_LEARNING_RATE_DECAY': True} -> 4.35%\n",
      "Training with /root/tf-hpolib/tf-hpo/src/config/HPV_14786929395168.ini is terminated properly\n",
      "{'DROPOUT_RATE': 0.75, 'BASE_LEARNING_RATE': 0.01, 'REGULARIZER_FACTOR': 0.25, 'USE_LEARNING_RATE_DECAY': True} -> 3.57%\n",
      "Training with /root/tf-hpolib/tf-hpo/src/config/HPV_14786930516908.ini is terminated properly\n",
      "{'DROPOUT_RATE': 0.25, 'BASE_LEARNING_RATE': 0.01, 'REGULARIZER_FACTOR': 0.25, 'USE_LEARNING_RATE_DECAY': True} -> 2.6%\n",
      "Training with /root/tf-hpolib/tf-hpo/src/config/HPV_14786931644213.ini is terminated properly\n",
      "{'DROPOUT_RATE': 1.0, 'BASE_LEARNING_RATE': 0.01, 'REGULARIZER_FACTOR': 0.5, 'USE_LEARNING_RATE_DECAY': True} -> 6.27%\n",
      "Training with /root/tf-hpolib/tf-hpo/src/config/HPV_14786932768886.ini is terminated properly\n",
      "{'DROPOUT_RATE': 0.75, 'BASE_LEARNING_RATE': 0.01, 'REGULARIZER_FACTOR': 0.5, 'USE_LEARNING_RATE_DECAY': True} -> 5.46%\n",
      "Training with /root/tf-hpolib/tf-hpo/src/config/HPV_14786933885582.ini is terminated properly\n",
      "{'DROPOUT_RATE': 0.25, 'BASE_LEARNING_RATE': 0.01, 'REGULARIZER_FACTOR': 0.5, 'USE_LEARNING_RATE_DECAY': True} -> 3.49%\n",
      "Training with /root/tf-hpolib/tf-hpo/src/config/HPV_14786935007720.ini is terminated properly\n",
      "{'DROPOUT_RATE': 1.0, 'BASE_LEARNING_RATE': 0.0001, 'REGULARIZER_FACTOR': 5e-05, 'USE_LEARNING_RATE_DECAY': True} -> 3.28%\n",
      "Training with /root/tf-hpolib/tf-hpo/src/config/HPV_14786936141311.ini is terminated properly\n",
      "{'DROPOUT_RATE': 0.75, 'BASE_LEARNING_RATE': 0.0001, 'REGULARIZER_FACTOR': 5e-05, 'USE_LEARNING_RATE_DECAY': True} -> 3.12%\n",
      "Training with /root/tf-hpolib/tf-hpo/src/config/HPV_14786937293756.ini is terminated properly\n",
      "{'DROPOUT_RATE': 0.25, 'BASE_LEARNING_RATE': 0.0001, 'REGULARIZER_FACTOR': 5e-05, 'USE_LEARNING_RATE_DECAY': True} -> 3.98%\n",
      "Training with /root/tf-hpolib/tf-hpo/src/config/HPV_14786938416936.ini is terminated properly\n",
      "{'DROPOUT_RATE': 1.0, 'BASE_LEARNING_RATE': 0.0001, 'REGULARIZER_FACTOR': 0.25, 'USE_LEARNING_RATE_DECAY': True} -> 6.69%\n",
      "Training with /root/tf-hpolib/tf-hpo/src/config/HPV_14786939541839.ini is terminated properly\n",
      "{'DROPOUT_RATE': 0.75, 'BASE_LEARNING_RATE': 0.0001, 'REGULARIZER_FACTOR': 0.25, 'USE_LEARNING_RATE_DECAY': True} -> 6.08%\n",
      "Training with /root/tf-hpolib/tf-hpo/src/config/HPV_14786940663930.ini is terminated properly\n",
      "{'DROPOUT_RATE': 0.25, 'BASE_LEARNING_RATE': 0.0001, 'REGULARIZER_FACTOR': 0.25, 'USE_LEARNING_RATE_DECAY': True} -> 6.16%\n",
      "Training with /root/tf-hpolib/tf-hpo/src/config/HPV_14786941775165.ini is terminated properly\n",
      "{'DROPOUT_RATE': 1.0, 'BASE_LEARNING_RATE': 0.0001, 'REGULARIZER_FACTOR': 0.5, 'USE_LEARNING_RATE_DECAY': True} -> 8.8%\n",
      "Training with /root/tf-hpolib/tf-hpo/src/config/HPV_14786942887539.ini is terminated properly\n",
      "{'DROPOUT_RATE': 0.75, 'BASE_LEARNING_RATE': 0.0001, 'REGULARIZER_FACTOR': 0.5, 'USE_LEARNING_RATE_DECAY': True} -> 8.16%\n",
      "Training with /root/tf-hpolib/tf-hpo/src/config/HPV_14786944019928.ini is terminated properly\n",
      "{'DROPOUT_RATE': 0.25, 'BASE_LEARNING_RATE': 0.0001, 'REGULARIZER_FACTOR': 0.5, 'USE_LEARNING_RATE_DECAY': True} -> 8.43%\n",
      "Training with /root/tf-hpolib/tf-hpo/src/config/HPV_14786945158817.ini is terminated properly\n",
      "{'DROPOUT_RATE': 1.0, 'BASE_LEARNING_RATE': 0.1, 'REGULARIZER_FACTOR': 5e-05, 'USE_LEARNING_RATE_DECAY': False} -> 2.07%\n",
      "Training with /root/tf-hpolib/tf-hpo/src/config/HPV_14786946257075.ini is terminated properly\n",
      "{'DROPOUT_RATE': 0.75, 'BASE_LEARNING_RATE': 0.1, 'REGULARIZER_FACTOR': 5e-05, 'USE_LEARNING_RATE_DECAY': False} -> 90.2%\n",
      "Training with /root/tf-hpolib/tf-hpo/src/config/HPV_14786947356429.ini is terminated properly\n",
      "{'DROPOUT_RATE': 0.25, 'BASE_LEARNING_RATE': 0.1, 'REGULARIZER_FACTOR': 5e-05, 'USE_LEARNING_RATE_DECAY': False} -> 90.2%\n",
      "Training with /root/tf-hpolib/tf-hpo/src/config/HPV_14786948466037.ini is terminated properly\n",
      "{'DROPOUT_RATE': 1.0, 'BASE_LEARNING_RATE': 0.1, 'REGULARIZER_FACTOR': 0.25, 'USE_LEARNING_RATE_DECAY': False} -> 90.2%\n",
      "Training with /root/tf-hpolib/tf-hpo/src/config/HPV_14786949553384.ini is terminated properly\n",
      "{'DROPOUT_RATE': 0.75, 'BASE_LEARNING_RATE': 0.1, 'REGULARIZER_FACTOR': 0.25, 'USE_LEARNING_RATE_DECAY': False} -> 90.2%\n",
      "Training with /root/tf-hpolib/tf-hpo/src/config/HPV_14786950649186.ini is terminated properly\n",
      "{'DROPOUT_RATE': 0.25, 'BASE_LEARNING_RATE': 0.1, 'REGULARIZER_FACTOR': 0.25, 'USE_LEARNING_RATE_DECAY': False} -> 4.81%\n",
      "Training with /root/tf-hpolib/tf-hpo/src/config/HPV_14786951754182.ini is terminated properly\n",
      "{'DROPOUT_RATE': 1.0, 'BASE_LEARNING_RATE': 0.1, 'REGULARIZER_FACTOR': 0.5, 'USE_LEARNING_RATE_DECAY': False} -> 89.9%\n",
      "Training with /root/tf-hpolib/tf-hpo/src/config/HPV_14786952854138.ini is terminated properly\n",
      "{'DROPOUT_RATE': 0.75, 'BASE_LEARNING_RATE': 0.1, 'REGULARIZER_FACTOR': 0.5, 'USE_LEARNING_RATE_DECAY': False} -> 89.9%\n",
      "Training with /root/tf-hpolib/tf-hpo/src/config/HPV_14786953973959.ini is terminated properly\n",
      "{'DROPOUT_RATE': 0.25, 'BASE_LEARNING_RATE': 0.1, 'REGULARIZER_FACTOR': 0.5, 'USE_LEARNING_RATE_DECAY': False} -> 89.9%\n",
      "Training with /root/tf-hpolib/tf-hpo/src/config/HPV_14786955096201.ini is terminated properly\n",
      "{'DROPOUT_RATE': 1.0, 'BASE_LEARNING_RATE': 0.01, 'REGULARIZER_FACTOR': 5e-05, 'USE_LEARNING_RATE_DECAY': False} -> 0.83%\n",
      "Training with /root/tf-hpolib/tf-hpo/src/config/HPV_14786956218834.ini is terminated properly\n",
      "{'DROPOUT_RATE': 0.75, 'BASE_LEARNING_RATE': 0.01, 'REGULARIZER_FACTOR': 5e-05, 'USE_LEARNING_RATE_DECAY': False} -> 0.76%\n",
      "Training with /root/tf-hpolib/tf-hpo/src/config/HPV_14786957333103.ini is terminated properly\n",
      "{'DROPOUT_RATE': 0.25, 'BASE_LEARNING_RATE': 0.01, 'REGULARIZER_FACTOR': 5e-05, 'USE_LEARNING_RATE_DECAY': False} -> 0.7%\n",
      "Training with /root/tf-hpolib/tf-hpo/src/config/HPV_14786958447427.ini is terminated properly\n",
      "{'DROPOUT_RATE': 1.0, 'BASE_LEARNING_RATE': 0.01, 'REGULARIZER_FACTOR': 0.25, 'USE_LEARNING_RATE_DECAY': False} -> 4.78%\n",
      "Training with /root/tf-hpolib/tf-hpo/src/config/HPV_14786959567719.ini is terminated properly\n",
      "{'DROPOUT_RATE': 0.75, 'BASE_LEARNING_RATE': 0.01, 'REGULARIZER_FACTOR': 0.25, 'USE_LEARNING_RATE_DECAY': False} -> 4.59%\n",
      "Training with /root/tf-hpolib/tf-hpo/src/config/HPV_14786960685522.ini is terminated properly\n",
      "{'DROPOUT_RATE': 0.25, 'BASE_LEARNING_RATE': 0.01, 'REGULARIZER_FACTOR': 0.25, 'USE_LEARNING_RATE_DECAY': False} -> 3.28%\n",
      "Training with /root/tf-hpolib/tf-hpo/src/config/HPV_14786961814161.ini is terminated properly\n",
      "{'DROPOUT_RATE': 1.0, 'BASE_LEARNING_RATE': 0.01, 'REGULARIZER_FACTOR': 0.5, 'USE_LEARNING_RATE_DECAY': False} -> 7.02%\n",
      "Training with /root/tf-hpolib/tf-hpo/src/config/HPV_14786962950578.ini is terminated properly\n",
      "{'DROPOUT_RATE': 0.75, 'BASE_LEARNING_RATE': 0.01, 'REGULARIZER_FACTOR': 0.5, 'USE_LEARNING_RATE_DECAY': False} -> 5.19%\n",
      "Training with /root/tf-hpolib/tf-hpo/src/config/HPV_14786964113913.ini is terminated properly\n",
      "{'DROPOUT_RATE': 0.25, 'BASE_LEARNING_RATE': 0.01, 'REGULARIZER_FACTOR': 0.5, 'USE_LEARNING_RATE_DECAY': False} -> 4.05%\n",
      "Training with /root/tf-hpolib/tf-hpo/src/config/HPV_14786965234640.ini is terminated properly\n",
      "{'DROPOUT_RATE': 1.0, 'BASE_LEARNING_RATE': 0.0001, 'REGULARIZER_FACTOR': 5e-05, 'USE_LEARNING_RATE_DECAY': False} -> 2.75%\n",
      "Training with /root/tf-hpolib/tf-hpo/src/config/HPV_14786966361958.ini is terminated properly\n",
      "{'DROPOUT_RATE': 0.75, 'BASE_LEARNING_RATE': 0.0001, 'REGULARIZER_FACTOR': 5e-05, 'USE_LEARNING_RATE_DECAY': False} -> 2.55%\n",
      "Training with /root/tf-hpolib/tf-hpo/src/config/HPV_14786967489634.ini is terminated properly\n",
      "{'DROPOUT_RATE': 0.25, 'BASE_LEARNING_RATE': 0.0001, 'REGULARIZER_FACTOR': 5e-05, 'USE_LEARNING_RATE_DECAY': False} -> 3.24%\n",
      "Training with /root/tf-hpolib/tf-hpo/src/config/HPV_14786968644689.ini is terminated properly\n",
      "{'DROPOUT_RATE': 1.0, 'BASE_LEARNING_RATE': 0.0001, 'REGULARIZER_FACTOR': 0.25, 'USE_LEARNING_RATE_DECAY': False} -> 6.08%\n",
      "Training with /root/tf-hpolib/tf-hpo/src/config/HPV_14786969771143.ini is terminated properly\n",
      "{'DROPOUT_RATE': 0.75, 'BASE_LEARNING_RATE': 0.0001, 'REGULARIZER_FACTOR': 0.25, 'USE_LEARNING_RATE_DECAY': False} -> 5.43%\n",
      "Training with /root/tf-hpolib/tf-hpo/src/config/HPV_14786970900145.ini is terminated properly\n",
      "{'DROPOUT_RATE': 0.25, 'BASE_LEARNING_RATE': 0.0001, 'REGULARIZER_FACTOR': 0.25, 'USE_LEARNING_RATE_DECAY': False} -> 5.27%\n",
      "Training with /root/tf-hpolib/tf-hpo/src/config/HPV_14786972028936.ini is terminated properly\n",
      "{'DROPOUT_RATE': 1.0, 'BASE_LEARNING_RATE': 0.0001, 'REGULARIZER_FACTOR': 0.5, 'USE_LEARNING_RATE_DECAY': False} -> 7.81%\n",
      "Training with /root/tf-hpolib/tf-hpo/src/config/HPV_14786973171735.ini is terminated properly\n",
      "{'DROPOUT_RATE': 0.75, 'BASE_LEARNING_RATE': 0.0001, 'REGULARIZER_FACTOR': 0.5, 'USE_LEARNING_RATE_DECAY': False} -> 7.27%\n",
      "Training with /root/tf-hpolib/tf-hpo/src/config/HPV_14786974308094.ini is terminated properly\n",
      "{'DROPOUT_RATE': 0.25, 'BASE_LEARNING_RATE': 0.0001, 'REGULARIZER_FACTOR': 0.5, 'USE_LEARNING_RATE_DECAY': False} -> 7.29%\n"
     ]
    }
   ],
   "source": [
    "use_decays = [True, False]\n",
    "learning_rates = [0.1, 0.01, 0.0001]\n",
    "regularization_factors = [5e-05, 0.25, 0.5]\n",
    "dropouts = [1., 0.75, 0.25]\n",
    "mixed_results = []\n",
    "for use_decay in use_decays:\n",
    "    for learning_rate in learning_rates:\n",
    "        for regularization_factor in regularization_factors:\n",
    "            for dropout in dropouts:    \n",
    "                params = {'USE_LEARNING_RATE_DECAY': use_decay, 'BASE_LEARNING_RATE': learning_rate, \\\n",
    "                      'REGULARIZER_FACTOR': regularization_factor, 'DROPOUT_RATE': dropout}\n",
    "                result = run(params)\n",
    "                #print str(params) + \" -> \" + str(result) + \"%\"\n",
    "                mixed_results[str(params)] = result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def test_run(params):\n",
    "    try:        \n",
    "        generator = HPVGenerator()\n",
    "        generator.setTemplate(TEMPLATE_PATH)\n",
    "        hpv_file = generator.generate(params, output_dir=CONFIG_PATH)\n",
    "                \n",
    "        train_manager = TrainingManager(LeNet5(mnist.import_dataset()))\n",
    "        train_manager.setTrainingDevices('gpu', NUM_GPUS)\n",
    "        \n",
    "        hpv = HPVManager(hpv_file, ini_dir=CONFIG_PATH)\n",
    "        return train_manager.run(hpv)\n",
    "           \n",
    "    except:\n",
    "        e = sys.exc_info()\n",
    "        print(\"Error: \" + str(e))\n",
    "        traceback.print_exc()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "LOG_PATH = \"../log/conv_params_test.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "({'conv2_depth': 64, 'dropout_rate': 0.5, 'conv1_depth': 32, 'OPTIMIZATION': 'Momentum', 'MOMENTUM_VALUE': 0.9, 'base_learning_rate': 0.01, 'filter_size': 5, 'init_stddev': 0.1, 'seed': 66478, 'BATCH_SIZE': 64, 'pooling_size': 4, 'num_epochs': 20, 'eval_frequency': 100, 'eval_batch_size': 64, 'FC1_WIDTH': 512, 'fc1_width': 512, 'momentum_value': 0.9, 'STRIDE_SIZE': 2, 'decay_rate': 0.95, 'optimization': 'Momentum', 'num_pooling': 2, 'POOLING_SIZE': 4, 'NUM_EPOCHS': 20, 'USE_LEARNING_RATE_DECAY': True, 'EVAL_FREQUENCY': 100, 'EVAL_BATCH_SIZE': 64, 'regularizer_factor': 0.0005, 'batch_size': 64, 'BASE_LEARNING_RATE': 0.01, 'padding': 'VALID', 'FILTER_SIZE': 5, 'INIT_WEIGHT_VALUE': 0.1, 'use_learning_rate_decay': True, 'CONV2_DEPTH': 64, 'DROPOUT_RATE': 0.5, 'CONV1_DEPTH': 32, 'DECAY_RATE': 0.95, 'REGULARIZER_FACTOR': 0.0005, 'INIT_STDDEV': 0.1, 'stride_size': 2, 'PADDING': 'VALID', 'SEED': 66478, 'NUM_POOLING': 2, 'init_weight_value': 0.1},)\n",
      "({'VALIDATION': False, 'TRAIN_DEVICE_ID': '/gpu:0', 'CREATED': '2016-11-17 19:08:19', 'EARLY_STOP_CHECK_EPOCHS': 1, 'output_log_file': '../log/conv_params_test.csv', 'created': '2016-11-17 19:08:19', 'test_device_id': '/gpu:0', 'train_device_id': '/gpu:0', 'early_stop_check_epochs': 1, 'TEST_DEVICE_ID': '/gpu:0', 'validation': False, 'OUTPUT_LOG_FILE': '../log/conv_params_test.csv'},)\n",
      "([64, 5, 5, 64],)\n",
      "(TensorShape([Dimension(64), Dimension(1600)]),)\n",
      "(TensorShape([Dimension(3136), Dimension(512)]),)\n",
      "(<type 'exceptions.ValueError'>, ValueError('Dimensions 1600 and 3136 are not compatible',), <traceback object at 0x7f5aff144950>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"models/cnn_model1.py\", line 79, in learn\n",
      "    y = self.train()\n",
      "  File \"models/cnn_model1.py\", line 100, in train\n",
      "    logits = self.createModel(self.train_data_node, True)\n",
      "  File \"models/cnn_model1.py\", line 377, in createModel\n",
      "    hidden = tf.nn.relu(tf.matmul(reshape, self.fc1_weights) + self.fc1_biases)\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/math_ops.py\", line 1346, in matmul\n",
      "    name=name)\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/gen_math_ops.py\", line 1271, in _mat_mul\n",
      "    transpose_b=transpose_b, name=name)\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/op_def_library.py\", line 703, in apply_op\n",
      "    op_def=op_def)\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py\", line 2312, in create_op\n",
      "    set_shapes_for_outputs(ret)\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py\", line 1704, in set_shapes_for_outputs\n",
      "    shapes = shape_func(op)\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/common_shapes.py\", line 94, in matmul_shape\n",
      "    inner_a.assert_is_compatible_with(inner_b)\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/tensor_shape.py\", line 108, in assert_is_compatible_with\n",
      "    % (self, other))\n",
      "ValueError: Dimensions 1600 and 3136 are not compatible\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "({'conv2_depth': 64, 'dropout_rate': 0.5, 'conv1_depth': 32, 'OPTIMIZATION': 'Momentum', 'MOMENTUM_VALUE': 0.9, 'base_learning_rate': 0.01, 'filter_size': 5, 'init_stddev': 0.1, 'seed': 66478, 'BATCH_SIZE': 64, 'pooling_size': 6, 'num_epochs': 20, 'eval_frequency': 100, 'eval_batch_size': 64, 'FC1_WIDTH': 512, 'fc1_width': 512, 'momentum_value': 0.9, 'STRIDE_SIZE': 2, 'decay_rate': 0.95, 'optimization': 'Momentum', 'num_pooling': 2, 'POOLING_SIZE': 6, 'NUM_EPOCHS': 20, 'USE_LEARNING_RATE_DECAY': True, 'EVAL_FREQUENCY': 100, 'EVAL_BATCH_SIZE': 64, 'regularizer_factor': 0.0005, 'batch_size': 64, 'BASE_LEARNING_RATE': 0.01, 'padding': 'VALID', 'FILTER_SIZE': 5, 'INIT_WEIGHT_VALUE': 0.1, 'use_learning_rate_decay': True, 'CONV2_DEPTH': 64, 'DROPOUT_RATE': 0.5, 'CONV1_DEPTH': 32, 'DECAY_RATE': 0.95, 'REGULARIZER_FACTOR': 0.0005, 'INIT_STDDEV': 0.1, 'stride_size': 2, 'PADDING': 'VALID', 'SEED': 66478, 'NUM_POOLING': 2, 'init_weight_value': 0.1},)\n",
      "({'VALIDATION': False, 'TRAIN_DEVICE_ID': '/gpu:0', 'CREATED': '2016-11-17 19:08:20', 'EARLY_STOP_CHECK_EPOCHS': 1, 'output_log_file': '../log/conv_params_test.csv', 'created': '2016-11-17 19:08:20', 'test_device_id': '/gpu:0', 'train_device_id': '/gpu:0', 'early_stop_check_epochs': 1, 'TEST_DEVICE_ID': '/gpu:0', 'validation': False, 'OUTPUT_LOG_FILE': '../log/conv_params_test.csv'},)\n",
      "([64, 4, 4, 64],)\n",
      "(TensorShape([Dimension(64), Dimension(1024)]),)\n",
      "(TensorShape([Dimension(3136), Dimension(512)]),)\n",
      "(<type 'exceptions.ValueError'>, ValueError('Dimensions 1024 and 3136 are not compatible',), <traceback object at 0x7f5aff003d88>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"models/cnn_model1.py\", line 79, in learn\n",
      "    y = self.train()\n",
      "  File \"models/cnn_model1.py\", line 100, in train\n",
      "    logits = self.createModel(self.train_data_node, True)\n",
      "  File \"models/cnn_model1.py\", line 377, in createModel\n",
      "    hidden = tf.nn.relu(tf.matmul(reshape, self.fc1_weights) + self.fc1_biases)\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/math_ops.py\", line 1346, in matmul\n",
      "    name=name)\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/gen_math_ops.py\", line 1271, in _mat_mul\n",
      "    transpose_b=transpose_b, name=name)\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/op_def_library.py\", line 703, in apply_op\n",
      "    op_def=op_def)\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py\", line 2312, in create_op\n",
      "    set_shapes_for_outputs(ret)\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py\", line 1704, in set_shapes_for_outputs\n",
      "    shapes = shape_func(op)\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/common_shapes.py\", line 94, in matmul_shape\n",
      "    inner_a.assert_is_compatible_with(inner_b)\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/tensor_shape.py\", line 108, in assert_is_compatible_with\n",
      "    % (self, other))\n",
      "ValueError: Dimensions 1024 and 3136 are not compatible\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "({'conv2_depth': 64, 'dropout_rate': 0.5, 'conv1_depth': 32, 'OPTIMIZATION': 'Momentum', 'MOMENTUM_VALUE': 0.9, 'base_learning_rate': 0.01, 'filter_size': 5, 'init_stddev': 0.1, 'seed': 66478, 'BATCH_SIZE': 64, 'pooling_size': 8, 'num_epochs': 20, 'eval_frequency': 100, 'eval_batch_size': 64, 'FC1_WIDTH': 512, 'fc1_width': 512, 'momentum_value': 0.9, 'STRIDE_SIZE': 2, 'decay_rate': 0.95, 'optimization': 'Momentum', 'num_pooling': 2, 'POOLING_SIZE': 8, 'NUM_EPOCHS': 20, 'USE_LEARNING_RATE_DECAY': True, 'EVAL_FREQUENCY': 100, 'EVAL_BATCH_SIZE': 64, 'regularizer_factor': 0.0005, 'batch_size': 64, 'BASE_LEARNING_RATE': 0.01, 'padding': 'VALID', 'FILTER_SIZE': 5, 'INIT_WEIGHT_VALUE': 0.1, 'use_learning_rate_decay': True, 'CONV2_DEPTH': 64, 'DROPOUT_RATE': 0.5, 'CONV1_DEPTH': 32, 'DECAY_RATE': 0.95, 'REGULARIZER_FACTOR': 0.0005, 'INIT_STDDEV': 0.1, 'stride_size': 2, 'PADDING': 'VALID', 'SEED': 66478, 'NUM_POOLING': 2, 'init_weight_value': 0.1},)\n",
      "({'VALIDATION': False, 'TRAIN_DEVICE_ID': '/gpu:0', 'CREATED': '2016-11-17 19:08:20', 'EARLY_STOP_CHECK_EPOCHS': 1, 'output_log_file': '../log/conv_params_test.csv', 'created': '2016-11-17 19:08:20', 'test_device_id': '/gpu:0', 'train_device_id': '/gpu:0', 'early_stop_check_epochs': 1, 'TEST_DEVICE_ID': '/gpu:0', 'validation': False, 'OUTPUT_LOG_FILE': '../log/conv_params_test.csv'},)\n",
      "([64, 2, 2, 64],)\n",
      "(TensorShape([Dimension(64), Dimension(256)]),)\n",
      "(TensorShape([Dimension(3136), Dimension(512)]),)\n",
      "(<type 'exceptions.ValueError'>, ValueError('Dimensions 256 and 3136 are not compatible',), <traceback object at 0x7f5afef52ab8>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"models/cnn_model1.py\", line 79, in learn\n",
      "    y = self.train()\n",
      "  File \"models/cnn_model1.py\", line 100, in train\n",
      "    logits = self.createModel(self.train_data_node, True)\n",
      "  File \"models/cnn_model1.py\", line 377, in createModel\n",
      "    hidden = tf.nn.relu(tf.matmul(reshape, self.fc1_weights) + self.fc1_biases)\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/math_ops.py\", line 1346, in matmul\n",
      "    name=name)\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/gen_math_ops.py\", line 1271, in _mat_mul\n",
      "    transpose_b=transpose_b, name=name)\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/op_def_library.py\", line 703, in apply_op\n",
      "    op_def=op_def)\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py\", line 2312, in create_op\n",
      "    set_shapes_for_outputs(ret)\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py\", line 1704, in set_shapes_for_outputs\n",
      "    shapes = shape_func(op)\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/common_shapes.py\", line 94, in matmul_shape\n",
      "    inner_a.assert_is_compatible_with(inner_b)\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/tensor_shape.py\", line 108, in assert_is_compatible_with\n",
      "    % (self, other))\n",
      "ValueError: Dimensions 256 and 3136 are not compatible\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "({'conv2_depth': 64, 'dropout_rate': 0.5, 'conv1_depth': 32, 'OPTIMIZATION': 'Momentum', 'MOMENTUM_VALUE': 0.9, 'base_learning_rate': 0.01, 'filter_size': 5, 'init_stddev': 0.1, 'seed': 66478, 'BATCH_SIZE': 64, 'pooling_size': 10, 'num_epochs': 20, 'eval_frequency': 100, 'eval_batch_size': 64, 'FC1_WIDTH': 512, 'fc1_width': 512, 'momentum_value': 0.9, 'STRIDE_SIZE': 2, 'decay_rate': 0.95, 'optimization': 'Momentum', 'num_pooling': 2, 'POOLING_SIZE': 10, 'NUM_EPOCHS': 20, 'USE_LEARNING_RATE_DECAY': True, 'EVAL_FREQUENCY': 100, 'EVAL_BATCH_SIZE': 64, 'regularizer_factor': 0.0005, 'batch_size': 64, 'BASE_LEARNING_RATE': 0.01, 'padding': 'VALID', 'FILTER_SIZE': 5, 'INIT_WEIGHT_VALUE': 0.1, 'use_learning_rate_decay': True, 'CONV2_DEPTH': 64, 'DROPOUT_RATE': 0.5, 'CONV1_DEPTH': 32, 'DECAY_RATE': 0.95, 'REGULARIZER_FACTOR': 0.0005, 'INIT_STDDEV': 0.1, 'stride_size': 2, 'PADDING': 'VALID', 'SEED': 66478, 'NUM_POOLING': 2, 'init_weight_value': 0.1},)\n",
      "({'VALIDATION': False, 'TRAIN_DEVICE_ID': '/gpu:0', 'CREATED': '2016-11-17 19:08:20', 'EARLY_STOP_CHECK_EPOCHS': 1, 'output_log_file': '../log/conv_params_test.csv', 'created': '2016-11-17 19:08:20', 'test_device_id': '/gpu:0', 'train_device_id': '/gpu:0', 'early_stop_check_epochs': 1, 'TEST_DEVICE_ID': '/gpu:0', 'validation': False, 'OUTPUT_LOG_FILE': '../log/conv_params_test.csv'},)\n",
      "([64, 1, 1, 64],)\n",
      "(TensorShape([Dimension(64), Dimension(64)]),)\n",
      "(TensorShape([Dimension(3136), Dimension(512)]),)\n",
      "(<type 'exceptions.ValueError'>, ValueError('Dimensions 64 and 3136 are not compatible',), <traceback object at 0x7f5afee20ab8>)\n",
      "{'PADDING': 'VALID', 'STRIDE_SIZE': 2, 'POOLING_SIZE': 8} -> None%\n",
      "{'PADDING': 'VALID', 'STRIDE_SIZE': 2, 'POOLING_SIZE': 6} -> None%\n",
      "{'PADDING': 'VALID', 'STRIDE_SIZE': 2, 'POOLING_SIZE': 10} -> None%\n",
      "{'PADDING': 'VALID', 'STRIDE_SIZE': 2, 'POOLING_SIZE': 4} -> None%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"models/cnn_model1.py\", line 79, in learn\n",
      "    y = self.train()\n",
      "  File \"models/cnn_model1.py\", line 100, in train\n",
      "    logits = self.createModel(self.train_data_node, True)\n",
      "  File \"models/cnn_model1.py\", line 377, in createModel\n",
      "    hidden = tf.nn.relu(tf.matmul(reshape, self.fc1_weights) + self.fc1_biases)\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/math_ops.py\", line 1346, in matmul\n",
      "    name=name)\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/gen_math_ops.py\", line 1271, in _mat_mul\n",
      "    transpose_b=transpose_b, name=name)\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/op_def_library.py\", line 703, in apply_op\n",
      "    op_def=op_def)\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py\", line 2312, in create_op\n",
      "    set_shapes_for_outputs(ret)\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py\", line 1704, in set_shapes_for_outputs\n",
      "    shapes = shape_func(op)\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/common_shapes.py\", line 94, in matmul_shape\n",
      "    inner_a.assert_is_compatible_with(inner_b)\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/tensor_shape.py\", line 108, in assert_is_compatible_with\n",
      "    % (self, other))\n",
      "ValueError: Dimensions 64 and 3136 are not compatible\n"
     ]
    }
   ],
   "source": [
    "# convolutional network hyperparameters \n",
    "paddings = ['VALID']#['SAME', 'VALID']\n",
    "maxpooling_window_sizes = [4, 6, 8, 10] # [1, 2, 4, 6, 8, 10]\n",
    "maxpooling_stride_sizes = [2]\n",
    "conv_results = {}\n",
    "for padding in paddings:\n",
    "    for maxpooling_window_size in maxpooling_window_sizes:\n",
    "        for maxpooling_stride_size in maxpooling_stride_sizes:\n",
    "            params = {'PADDING':padding, 'POOLING_SIZE': maxpooling_window_size, 'STRIDE_SIZE' : maxpooling_stride_size }\n",
    "            result = run(params)\n",
    "            #print str(params) + \" -> \" + str(result) + \"%\"\n",
    "            conv_results[str(params)] = result\n",
    "for key in conv_results:\n",
    "    print key + \" -> \" + str(conv_results[key]) +  \"%\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
